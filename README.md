# A Comparison of Machine Learning Classifiers for Sign Language Recognition
In recent years, enormous research is progressing in the field of Computer Vision and Human Computer Interaction where hand gestures play a vital role. Hand gestures are more powerful means of communication for hearing impaired when they communicate to the normal people everywhere in day to day life. As the normal people find little difficulty in recognizing and interpreting the meaning of sign language expressed by the hearing impaired, it is inevitable to have an interpreter for translation of sign language. To overcome this difficulty, an automatic hand gesture recognition system which translates the sign language into text needs to be developed.
In this paper, we focus on the core part of sign language recognition system in which an efficient and effective machine learning model is required. We used a public ally available Sign Language MNIST dataset and apply state of the art classifiers on it and provide a performance comparison of them. KNN, SVM and neural networks provide good results, but deep learning methods out perform among all the classifiers.
